# Tutoriel : Analyse et PrÃ©paration des DonnÃ©es avec Python ğŸğŸ’»

---

# 1ï¸âƒ£ Importer les BibliothÃ¨ques ğŸ“¥

Avant tout, nous devons importer des bibliothÃ¨ques Python essentielles, comme Pandas pour manipuler les donnÃ©es et `requests` pour tÃ©lÃ©charger des fichiers en ligne.

```python
import warnings, requests, zipfile, io
import pandas as pd
from scipy.io import arff

# Pour ignorer les avertissements
warnings.simplefilter('ignore')
```

**Challenge** ğŸŒŸ: Pourquoi utilisons-nous la bibliothÃ¨que `warnings` dans ce code ?

**RÃ©ponse** : Nous utilisons `warnings` pour ignorer les messages dâ€™avertissement qui peuvent apparaÃ®tre lors de l'exÃ©cution du code, rendant la sortie plus propre et facile Ã  lire.

---

# 2ï¸âƒ£ TÃ©lÃ©chargement des DonnÃ©es ğŸ’¾

Ensuite, nous allons tÃ©lÃ©charger et extraire un fichier contenant les donnÃ©es sur la colonne vertÃ©brale.

```python
f_zip = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00212/vertebral_column_data.zip'
r = requests.get(f_zip, stream=True)
Vertebral_zip = zipfile.ZipFile(io.BytesIO(r.content))
Vertebral_zip.extractall()
```

**Challenge** ğŸŒŸ: Quelle est l'utilitÃ© de `io.BytesIO(r.content)` dans ce code ?

**RÃ©ponse** : `io.BytesIO(r.content)` transforme le contenu tÃ©lÃ©chargÃ© en un format binaire pour que `ZipFile` puisse l'ouvrir directement, sans qu'on ait besoin de le sauvegarder en tant que fichier temporaire.

---

# 3ï¸âƒ£ Charger les DonnÃ©es et les Visualiser ğŸ‘€

Nous allons maintenant charger les donnÃ©es extraites et les afficher pour voir leur structure.

```python
data = arff.loadarff('column_2C_weka.arff')
df = pd.DataFrame(data[0])
df.head()
```

**Challenge** ğŸŒŸ: Pourquoi utilisons-nous `pd.DataFrame(data[0])` au lieu de `data` directement ?

**RÃ©ponse** : `data` est un format spÃ©cifique au module `arff`, qui ne peut pas Ãªtre manipulÃ© facilement. En utilisant `pd.DataFrame(data[0])`, nous convertissons `data` en un DataFrame Pandas, plus simple Ã  manipuler pour l'analyse.

---

# 4ï¸âƒ£ Explorer les DonnÃ©es ğŸ”

L'exploration de donnÃ©es est cruciale pour comprendre ce que chaque colonne reprÃ©sente et les valeurs qu'elle contient.

```python
df.info()
df.describe()
```

**Challenge** ğŸŒŸ: Quelles informations obtenons-nous de la commande `df.describe()` ?

**RÃ©ponse** : `df.describe()` donne des statistiques descriptives (comme la moyenne, le minimum, et le maximum) pour chaque colonne numÃ©rique, ce qui nous aide Ã  comprendre la distribution de ces colonnes.

---

# 5ï¸âƒ£ Nettoyage et PrÃ©paration des DonnÃ©es ğŸ§¹

Avant d'analyser, il est important de nettoyer les donnÃ©es, comme enlever les valeurs manquantes ou mal formatÃ©es.

```python
df['class'] = df['class'].str.decode("utf-8")  # DÃ©coder les classes en texte lisible
df.dropna(inplace=True)  # Supprime les lignes avec des valeurs manquantes
```

**Challenge** ğŸŒŸ: Pourquoi devons-nous utiliser `str.decode("utf-8")` pour la colonne `class` ?

**RÃ©ponse** : La colonne `class` contient des valeurs encodÃ©es en binaire (comme `b'Abnormal'`). En utilisant `str.decode("utf-8")`, nous convertissons ces valeurs en chaÃ®nes de caractÃ¨res lisibles.

---

# 6ï¸âƒ£ Analyse Exploratoire des DonnÃ©es (EDA) ğŸ“Š

Maintenant, explorons les donnÃ©es pour mieux comprendre leurs distributions et relations.

```python
import seaborn as sns
import matplotlib.pyplot as plt

# Afficher la distribution de chaque colonne
sns.pairplot(df, hue="class")
plt.show()
```

**Challenge** ğŸŒŸ: Ã€ quoi sert `hue="class"` dans le `pairplot` ?

**RÃ©ponse** : Le paramÃ¨tre `hue="class"` permet de colorer les points selon leur classe (`Normal` ou `Abnormal`), facilitant la visualisation des diffÃ©rences entre les classes dans le graphique.

---

# 7ï¸âƒ£ ModÃ©lisation ğŸ§ 

Une fois les donnÃ©es prÃªtes, nous pouvons entraÃ®ner un modÃ¨le de Machine Learning pour prÃ©dire la classification.

```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Diviser les donnÃ©es en train et test
X = df.drop("class", axis=1)
y = df["class"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# EntraÃ®ner un modÃ¨le
model = RandomForestClassifier()
model.fit(X_train, y_train)

# PrÃ©dire et Ã©valuer
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))
```

**Challenge** ğŸŒŸ: Que signifie `test_size=0.2` dans `train_test_split` ?

**RÃ©ponse** : `test_size=0.2` indique que 20 % des donnÃ©es seront utilisÃ©es pour lâ€™ensemble de test, et 80 % pour lâ€™entraÃ®nement, assurant une bonne rÃ©partition pour Ã©valuer le modÃ¨le.

---

# 8ï¸âƒ£ Sauvegarder et DÃ©ployer le ModÃ¨le ğŸš€

Enfin, il est souvent utile de sauvegarder le modÃ¨le pour un futur dÃ©ploiement.

```python
import joblib

# Sauvegarder le modÃ¨le
joblib.dump(model, 'vertebral_model.pkl')

# Charger le modÃ¨le pour l'utiliser
loaded_model = joblib.load('vertebral_model.pkl')
```

**Challenge** ğŸŒŸ: Pourquoi est-il important de sauvegarder un modÃ¨le aprÃ¨s l'entraÃ®nement ?

**RÃ©ponse** : Sauvegarder le modÃ¨le permet de lâ€™utiliser ultÃ©rieurement sans avoir Ã  le rÃ©entraÃ®ner, ce qui Ã©conomise du temps et des ressources, notamment pour le dÃ©ploiement dans des applications.

---

# ğŸš€ Conclusion ğŸ‰

Bravo dâ€™avoir suivi ce tutoriel ! ğŸ‘ Vous avez appris Ã  :
- Importer et prÃ©parer des donnÃ©es ğŸ—‚ï¸
- Explorer des donnÃ©es ğŸ“Š
- EntraÃ®ner et Ã©valuer un modÃ¨le ğŸ§ 
- Sauvegarder votre travail pour une utilisation ultÃ©rieure ğŸ’¾

**Challenge final** ğŸŒŸ: Comment utiliseriez-vous ce modÃ¨le pour prÃ©dire de nouvelles donnÃ©es ?

**RÃ©ponse** : Pour prÃ©dire de nouvelles donnÃ©es, vous chargeriez le modÃ¨le sauvegardÃ© avec `joblib.load`, puis utiliseriez `loaded_model.predict(new_data)` oÃ¹ `new_data` est un DataFrame contenant les nouvelles observations Ã  prÃ©dire. 

Bon apprentissage et continuez Ã  pratiquer pour maÃ®triser ces concepts ! ğŸ˜Š
